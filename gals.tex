Ein GALS System -- GALS steht für "`Globally asynchronous, locally synchronous"' -- besteht aus mehreren synchronen Komponenten, die asynchron miteinander kommunizieren.
Formal kann ein synchrones System $\alpha$ vollständig als ein 4-Tupel
\[ \alpha = (I,O,S,t,f) \]
mit den folgenden Komponenten beschrieben werden ($V$ sei hier die Menge aller möglichen Variablen):
\begin{itemize}
\item Eine Menge von Eingabevariablen $I\subseteq V$, also beispielsweise $I=\{x,y\}$, wenn ein System mit zwei Eingabevariablen spezifiziert werden soll.
\item Eine Menge von Ausgabevariablen $O\subseteq V$.
\item Die Zustandsmenge $S$, die alle möglichen internen Zustände des Systems darstellt.
\item Einer Zuordnungsfunktion $t : I\cup O\rightarrow {Set}$ die jeder Variable einen Typen zuordnet.
\item Der eigentlichen Auswertungsfunktion $f : S\times \left(\prod_{v\in I} t(v)\right)\rightarrow S\times\left(\prod_{v\in O} t(v)\right)$, die also jeder Kombination aus Eingaben und internen Zuständen eine Ausgabe und einen neuen Zustand zuordnet.
\end{itemize}
Aus dieser Definition ergibt sich, dass synchrone Komponenten deterministisch sind, also bei gleichem internen Zustand und gleicher Eingabe immer die gleiche Ausgabe produzieren.

Mit dieser Definition lässt sich ein GALS-System $\gamma$ als ein Tupel der Form
\[ \gamma = (\mathcal{A},\mathcal{C}) \]
darstellen, wobei die Komponenten folgende Bedeutung haben:
\begin{itemize}
\item $\mathcal{A}$ ist eine Menge von synchronen Komponenten.
\item Die Relation $\mathcal{C}\subseteq V\times V$ gibt an, welche Ausgangsvariablen mit welchen Eingangsvariablen verknüpft sind.
\end{itemize}

\section{Semantik}
Diese Defintionen geben natürlich noch keinen Aufschluss über die Interpretationsweise der so spezifizierten GALS-Systeme.
Sie geben lediglich Aufschluss über die Verknüpfung der einzelnen synchronen Komponenten, nicht aber über deren Ausführung.
Tatsächlich bieten sich eine Vielzahl von Möglichkeiten an, ein gegebenes GALS-System auszuführen.
Einige davon sollen hier vorgestellt werden.

\section{Synchrone Ausführung}
Bei der synchronen Ausführung führen alle Systeme gleichzeitig ihren Berechnungsschritt aus.
Da eine echte Gleichzeitigkeit aber von SPIN nicht unterstützt wird, muss sie dadurch angenähert werden, dass die Komponenten zwar nacheinander ihre Schritte ausführen, aber dies  immer in der gleichen Reihenfolge tun.

\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \node[fill=d1,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_1$] at (0,0) {};
    \node[fill=d2,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_2$] at (0.5,0) {};
    \node[fill=d3,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_3$] at (1,0) {};

    \node[fill=d1,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_1$] at (1.5,0) {};
    \node[fill=d2,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_2$] at (2,0) {};
    \node[fill=d3,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_3$] at (2.5,0) {};

    \node at (3,0) {\dots};
    
  \end{tikzpicture}
  \caption{Synchrone Ausführung}
  \label{fig:synchronized_execution}
\end{figure}

In Abbildung \ref{fig:synchronized_execution} wird eine mögliche Ausführung der drei Prozesse $P_1$, $P_2$ und $P_3$ gezeigt.
Andere Ausführungsmöglichkeiten unterscheiden sich nur durch die Reihenfolge, in der die Prozesse ihren Berechnungsschritt ausführen.
Für ein System mit $n$ Prozessen gibt es also $n!$ Möglichkeiten der Ausführung.

Vorteile dieser Architektur sind eine extrem einfache Implementierung, sowie wenige Ausführungsreihenfolgen, die bei der Verifikation in Betracht gezogen werden müssen.
Das zu verifizierende Zustandsmodell des Systems hat also sehr viel weniger Zustände als die der anderen Architekturen.
Der Nachteil ist jedoch, dass es für viele Szenarien sehr unrealistisch ist, perfekte Synchronität zu fordern.
In Kommunikationsnetzen bedeuten schon minimale Verzögerungen bei der Zustellung von Nachrichten, dass Prozesse nicht mehr echt synchron laufen, selbst wenn ihre Uhren genau gleich gehen.

\section{Vollständig asynchrones System}
%In der vollständig asynchronenen Semantik können Komponenten zu jedem Zeitpunkt, unabhängig von dem Ausführungsstand der anderen, einen Schritt ausführen.
%Das bedeutet also, dass auch Extremfälle wie der, bei dem nur eine Komponente die gesamte Zeit Schritte ausführt, berücksichtigt werden.
%Diese Semantik deckt zwar jede Ausführungsreihenfolge der Komponenten ab, ist aber nicht unbedingt realistisch.
Im Gegensatz zur synchronen Architektur steht die vollständig asynchrone: 
Hier kann zu jedem Zeitpunkt jeder Prozess unabhängig vom Fortschritt der anderen einen Berechnungsschritt ausführen.
Eine Mögliche asynchrone Ausführung von drei Prozessen ist in Abbildung \ref{fig:asynchronous_execution} gezeigt.
\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    \node[fill=d2,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_2$] at (0,0) {};
    \node[fill=d2,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_2$] at (0.5,0) {};
    \node[fill=d2,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_2$] at (1,0) {};
    \node[fill=d3,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_3$] at (1.5,0) {};
    \node[fill=d3,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_3$] at (2,0) {};
    \node[fill=d3,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_3$] at (2.5,0) {};
    \node[fill=d1,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_1$] at (3,0) {};
    \node[fill=d3,draw=black,minimum height=1cm,minimum width=0.5cm,label=below:$P_3$] at (3.5,0) {};
    \node at (4,0) {\dots};
  \end{tikzpicture}
  \caption{Asynchrone Ausführung}
  \label{fig:asynchronous_execution}
\end{figure}

Eine asynchrone Architektur löst das Problem der synchronen Architektur, indem sie sämtliche theoretisch mögliche Verschachtelungen der Ausführungen der Prozesse bei der Verifikation berücksichtigt.
Dies führt aber zu zwei neuen Problemen:
Zum einen nimmt die Zustandsgröße des Systems eventuell gewaltig zu; $n$ Prozesse haben nach $m$ Ausführungsschritten bereits $n^m$ mögliche Ausführungen.
Zwar führen meist viele unterschiedliche Verschachtelungen zu den selben Zuständen, in diesem Fall kann die Technik der "`partial order reduction"'\cite{partial_order_reduction} verwendet werden, aber im schlimmsten Fall führt eine vollständig asynchrone Architektur zu einer gewaltigen Zustandsexplosion.
Das zweite Problem ist, dass diese Architektur auch extrem unrealistische Ausführungen in Erwägung zieht:
Ein Prozess kann zum Beispiel immer rechnen, während ein anderer nie zum Zuge kommt.
In der Verifikation können so Fehlerzustände erkannt werden, die in der Realität nie vorkommen.

\begin{figure}[h]
  \centering
  \includegraphics[scale=.5]{async}
  \caption{Mögliche Ausführungspfade eines asynchronen Systems}
  \label{fig:asynchronous_paths}
\end{figure}
\section{Asynchrone Ausführung mit Fairness}
Um das Problem zu umgehen, dass einzelne Prozesse "`verhungern"', also nie einen Rechenschritt ausführen dürfen, kann man so genannte \emph{Fairness}-Kriterien definieren:
Diese besagen, dass nur Ausführungen für die Verifikation in Betracht gezogen werden, in denen jeder Prozess immer mal wieder an die Reihe kommt.
SPIN unterstützt die Modellierung von Fairness-Kriterien durch die Definition von Labels, die immer mal wieder erreicht werden müssen, damit die Ausführung in Betracht gezogen wird.
\section{Asynchrone Ausführung mit Schranken}
%Um die Probleme der vollständig asynchronen Ausführung zu umgehen kann man die Asynchronität soweit begrenzen, dass die Anzahl der ausgeführten Schritte nie um mehr als einen festen Wert divergiert.
Obwohl das Hinzufügen von Fairness-Eigenschaften die Fälle entfernt, in denen ein Prozess niemals zur Ausführung kommt, so werden immer noch extrem unrealistische Szenarien betrachtet:
In der Realität wird es beispielsweise nie vorkommen, dass ein Prozess nur ein mal einen Berechnungsschritt durchführt, während ein anderer im gleichen Zeitraum 1000 ausführt.
Wesentlich realistischere Ausführungen erreicht man, wenn einzelnen Prozessen nur für einen gewissen Zeitraum erlaubt, mehr oder weniger Schritte als die anderen auszuführen.
Hierzu zählt man die Berechnungsschritte, die jeder Prozess bereits ausgeführt hat und überprüft, dass zu jedem Zeitpunkt der Verifikation die Bedingung "`Keine zwei Prozesse liegen um mehr als $x$ Berechnungsschritte von einander entfernt"' erfüllt ist.

